{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import fasttext\n",
    "import time\n",
    "from langdetect import detect\n",
    "try:\n",
    "    from detoxify import Detoxify\n",
    "except ImportError:\n",
    "    !pip install detoxify\n",
    "    from detoxify import Detoxify\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751369ca",
   "metadata": {},
   "source": [
    "# Configuration & Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = '../data/raw/mainpipe_data_v1.jsonl'\n",
    "OUTPUT_PATH = '../data/processed/cleaned_dataset.jsonl'\n",
    "SAMPLE_SIZE = 1000 # Number of samples for expensive checks\n",
    "PLOTS_DIR = '../reports/plots/'\n",
    "LANG_MODEL_PATH = '../data/lid.176.bin'\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7a7f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "if os.path.exists(INPUT_PATH):\n",
    "    print(f\"Loading dataset from {INPUT_PATH}...\")\n",
    "    df_in = pd.read_json(INPUT_PATH, lines=True)\n",
    "    print(f\"Loaded {len(df_in):,} documents.\")\n",
    "else:\n",
    "    print(f\"ERROR: File not found at {INPUT_PATH}. Please ensure you have downloaded the dataset.\")\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    print(f\"Loading dataset from {OUTPUT_PATH}...\")\n",
    "    df_out = pd.read_json(OUTPUT_PATH, lines=True)\n",
    "    print(f\"Loaded {len(df_out):,} documents.\")\n",
    "else:\n",
    "    print(f\"ERROR: File not found at {OUTPUT_PATH}. Please ensure the pipeline has been run successfully.\")\n",
    "    # Creating an empty DataFrame to allow the rest of the script to run without crashing, for demonstration purposes\n",
    "    df_out = pd.DataFrame({'doc_id': [], 'text': [], 'char_count': [], 'word_count': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea81207",
   "metadata": {},
   "source": [
    "## 1. Pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3183f29",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Values from count report (after running the pipeline):\n",
    "total_input = len(df_in)\n",
    "after_ingest = 201457\n",
    "after_filter = 160062\n",
    "after_dedup = len(df_out)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "categories = ['Input\\nRecords', 'After\\nIngestion', 'After\\nFiltering', 'After\\nDeduplication']\n",
    "values = [total_input, after_ingest, after_filter, after_dedup]\n",
    "colors_bar = ['Orange', 'Red', 'Blue', 'Green']\n",
    "bars = plt.bar(categories, values, color=colors_bar, edgecolor='black', width=0.6)\n",
    "plt.ylabel('Count')\n",
    "        #plt.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    percentage = (height / total_input * 100) if total_input > 0 else 0\n",
    "    if percentage < 100:\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{int(height):,}\\n({percentage:.1f}%)', ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "    else:\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{int(height):,}', ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'pipeline_steps.png'), bbox_inches='tight')\n",
    "print(\"Saved: pipeline_steps.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d9963",
   "metadata": {},
   "source": [
    "## 2. Histogram of lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9d90e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def wordschar_count(df):\n",
    "    if not df.empty:\n",
    "        if 'char_count' not in df.columns:\n",
    "            df['char_length'] = df['text'].str.len()\n",
    "        else:\n",
    "            df['char_length'] = df['char_count']\n",
    "        if 'word_count' not in df.columns:\n",
    "            df['word_count'] = df['text'].str.split().str.len()\n",
    "        return (df['char_length'], df['word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d4658",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# We analyze document lengths and check for HTML artifacts or non-printable characters.\n",
    "\n",
    "char_in, words_in = wordschar_count(df_in)\n",
    "char_out, words_out = wordschar_count(df_out)\n",
    "\n",
    "print(f\"Mean Length (input): {char_in.mean():.0f} chars\")\n",
    "print(f\"Min Length (input): {char_in.min()} chars\")\n",
    "print(f\"Max Length (input): {char_in.max()} chars\")\n",
    "print(f\"Mean Length (output): {char_out.mean():.0f} chars\")\n",
    "print(f\"Min Length (output): {char_out.min()} chars\")\n",
    "print(f\"Max Length (output): {char_out.max()} chars\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "ax[0,0].hist(char_in, bins=np.logspace(1,5,25), edgecolor = 'k',\n",
    "             color='Orange')\n",
    "ax[0,0].axvline(np.mean(char_in), color = 'Red', ls = '--', lw=2, label = f'Avg. input = {char_in.mean():.0f}')\n",
    "ax[0,0].axvline(np.mean(char_out), color = 'Blue', ls = '--', lw=2, label = f'Avg. output = {char_out.mean():.0f}')\n",
    "ax[0,0].set_title(\"Character Length Distribution\")\n",
    "ax[0,0].set_xlim([1,1e5])\n",
    "ax[0,0].set_ylabel('Count')\n",
    "ax[0,0].set_xscale('log')\n",
    "ax[0,0].legend(frameon=False)\n",
    "\n",
    "ax[0,1].hist(words_in, bins=np.logspace(1,4,25), edgecolor = 'k',\n",
    "             color='Orange')\n",
    "ax[0,1].axvline(np.mean(words_in), color = 'Red', ls = '--', lw=2, label = f'Avg. input = {words_in.mean():.0f}')\n",
    "ax[0,1].axvline(np.mean(words_out), color = 'Blue', ls = '--', lw=2, label = f'Avg. output = {words_out.mean():.0f}')\n",
    "ax[0,1].set_title(\"Words Length Distribution\")\n",
    "ax[0,1].legend(frameon=False)\n",
    "ax[0,1].set_xlim([1,1e4])\n",
    "ax[0,1].set_xscale('log')\n",
    "\n",
    "ax[1,0].hist(char_out, bins=np.logspace(1,5,25), edgecolor = 'k',\n",
    "             color='Green')\n",
    "ax[1,0].axvline(np.mean(char_in), color = 'Red', ls = '--', lw=2, label = f'Avg. input = {char_in.mean():.0f}')\n",
    "ax[1,0].axvline(np.mean(char_out), color = 'Blue', ls = '--', lw=2, label = f'Avg. output = {char_out.mean():.0f}')\n",
    "ax[1,0].legend(frameon=False)\n",
    "ax[1,0].set_xlim([1,1e5])\n",
    "ax[1,0].set_xscale('log')\n",
    "ax[1,0].set_ylabel('Count')\n",
    "ax[1,0].set_xlabel('Character length')\n",
    "\n",
    "ax[1,1].hist(words_out, bins=np.logspace(1,4,25), edgecolor = 'k',\n",
    "             color='Green')\n",
    "ax[1,1].axvline(np.mean(words_in), color = 'Red', ls = '--', lw=2, label = f'Avg. input = {words_in.mean():.0f}')\n",
    "ax[1,1].axvline(np.mean(words_out), color = 'Blue', ls = '--', lw=2, label = f'Avg. output = {words_out.mean():.0f}')\n",
    "ax[1,1].legend(frameon=False)\n",
    "ax[1,1].set_xlim([1,1e4])\n",
    "ax[1,1].set_xscale('log')\n",
    "ax[1,1].set_xlabel('Word length')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'Char_Words_Dist.png'), bbox_inches='tight')\n",
    "print(\"Saved: Char_Words_Dist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae68b99",
   "metadata": {},
   "source": [
    "## 3. Integrity checks (Boilerplate & artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0fb25",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Regex for common HTML tags left over \n",
    "html_re = re.compile(r'<[^>]+>')\n",
    "# Regex for excessive whitespace \n",
    "space_re = re.compile(r'\\s{4,}')\n",
    "code_re = re.compile(\n",
    "            r'\\b(function|var|const|let|=>|console\\.log|document\\.getElementById|'\n",
    "            r'window\\.|return|import|export|class|def|printf|iostream)\\b'\n",
    "        )\n",
    "\n",
    "#sample_check = df.sample(max(len(df), 5000))\n",
    "\n",
    "html_hits_in = df_in['text'].apply(lambda x: bool(html_re.search(x))).sum()\n",
    "code_hits_in = df_in['text'].apply(lambda x: bool(code_re.search(x))).sum()\n",
    "space_hits_in = df_in['text'].apply(lambda x: bool(space_re.search(x))).sum()\n",
    "code_hits_out = df_out['text'].apply(lambda x: bool(code_re.search(x))).sum()\n",
    "html_hits_out = df_out['text'].apply(lambda x: bool(html_re.search(x))).sum()\n",
    "space_hits_out = df_out['text'].apply(lambda x: bool(space_re.search(x))).sum()\n",
    "\n",
    "print(\"\\nIntegrity Scan\")\n",
    "print(f\"- Documents with HTML artifacts (input): {html_hits_in} ({html_hits_in/len(df_in):.1%})\")\n",
    "print(f\"- Documents with code (input): {code_hits_in} ({code_hits_in/len(df_in):.1%})\")\n",
    "print(f\"- Documents with excessive whitespace (input): {space_hits_in} ({space_hits_in/len(df_in):.1%})\")\n",
    "print(f\"- Documents with HTML artifacts (output): {html_hits_out} ({html_hits_out/len(df_out):.1%})\")\n",
    "print(f\"- Documents with code (output): {code_hits_out} ({code_hits_out/len(df_out):.1%})\")\n",
    "print(f\"- Documents with excessive whitespace (output): {space_hits_out} ({space_hits_out/len(df_out):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb291b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "categories = [\"HTML\", \"Code\", \"Whitespace\"]\n",
    "\n",
    "in_values = [html_hits_in, code_hits_in, space_hits_in]\n",
    "out_values = [html_hits_out, code_hits_out, space_hits_out]\n",
    "percentage_in = [v / len(df_in) * 100 for v in in_values]\n",
    "percentage_out = [v / len(df_out) * 100 for v in out_values]\n",
    "\n",
    "x = np.arange(len(categories))      # positions for categories\n",
    "width = 0.35                        # bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "bars_in = ax.bar(x - width/2, in_values, width, color = 'orange', label='Input')\n",
    "bars_out = ax.bar(x + width/2, out_values, width, color = 'green', label='Output')\n",
    "for bar, pct in zip(bars_in, percentage_in):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height, f\"{pct:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "for bar, pct in zip(bars_out, percentage_out):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height, f\"{pct:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Integrity Check Artifacts\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'Integrity_Check.png'), bbox_inches='tight')\n",
    "print(\"Saved: Integrity_Check.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26b27f",
   "metadata": {},
   "source": [
    "## 4a. Safety: PII check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce157f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# We verify that PII has been redacted (checking for `<EMAIL>` tags vs real emails) and perform a heuristic scan for toxicity.\n",
    "\n",
    "def check_PII(df):\n",
    "    if not df.empty:\n",
    "        redaction_tag_re = re.compile(r'<EMAIL>|<IP>|<PHONE>')\n",
    "        email_leak_re = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "        ip_leak_re = re.compile(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b')\n",
    "        phone_leak_re = re.compile(r'\\b(?:\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b')\n",
    "\n",
    "        redaction_counts = df['text'].str.count(redaction_tag_re).sum()\n",
    "\n",
    "        e_leaks = df['text'].apply(lambda x: len(email_leak_re.findall(x)))\n",
    "        ip_leaks = df['text'].apply(lambda x: len(ip_leak_re.findall(x)))\n",
    "        phone_leaks = df['text'].apply(lambda x: len(phone_leak_re.findall(x)))\n",
    "        total_eleaks = e_leaks.sum()\n",
    "        total_ipleaks = ip_leaks.sum()\n",
    "        total_phoneleaks = phone_leaks.sum()\n",
    "\n",
    "        print(\"\\nPII Safety Analysis:\")\n",
    "        print(f\"- Total Redaction Tags Found (<EMAIL>, etc): {redaction_counts:,}\")\n",
    "        print(f\"- Potential Email Leaks found: {total_eleaks:,}\")\n",
    "        print(f\"- Potential IP Leaks found: {total_ipleaks:,}\")\n",
    "        print(f\"- Potential Phone Leaks found: {total_phoneleaks:,}\")\n",
    "        print(f\"- Documents with email leaks: {len(df[e_leaks > 0]):,}\")\n",
    "        print(f\"- Documents with ip leaks: {len(df[ip_leaks > 0]):,}\")\n",
    "        print(f\"- Documents with phone leaks: {len(df[phone_leaks > 0]):,}\")\n",
    "        \n",
    "        # Inspect a redaction example\n",
    "        email_redacted_sample = df[df['text'].str.contains(\"<EMAIL>\", na=False)].head(1)\n",
    "        phone_redacted_sample = df[df['text'].str.contains(\"<PHONE>\", na=False)].head(1)\n",
    "        ip_redacted_sample = df[df['text'].str.contains(\"<IP>\", na=False)].head(1)\n",
    "        if not email_redacted_sample.empty:\n",
    "            print(\"\\n--- Redaction Example ---\")\n",
    "            print(email_redacted_sample.iloc[0]['text'][:300] + \"...\")\n",
    "        if not phone_redacted_sample.empty:\n",
    "            print(\"\\n--- Redaction Example ---\")\n",
    "            print(phone_redacted_sample.iloc[0]['text'][:300] + \"...\")\n",
    "        if not ip_redacted_sample.empty:\n",
    "            print(\"\\n--- Redaction Example ---\")\n",
    "            print(ip_redacted_sample.iloc[0]['text'][:300] + \"...\")\n",
    "        return redaction_counts, total_eleaks, total_ipleaks, total_phoneleaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4e253",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "red_in, eleaks_in, ipleaks_in, phoneleaks_in = check_PII(df_in)\n",
    "red_out, eleaks_out, ipleaks_out, phoneleaks_out = check_PII(df_out)\n",
    "\n",
    "categories = [\"Email\", \"Phone\", \"IP\"]\n",
    "\n",
    "PII_in = [eleaks_in, ipleaks_in, phoneleaks_in]\n",
    "PII_out = [eleaks_out, ipleaks_out, phoneleaks_out]\n",
    "PII_perc_in = [v / len(df_in) * 100 for v in PII_in]\n",
    "PII_perc_out = [v / len(df_out) * 100 for v in PII_out]\n",
    "\n",
    "x = np.arange(len(categories))      # positions for categories\n",
    "width = 0.35                        # bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "bars_in = ax.bar(x - width/2, PII_in, width, color = 'orange', label='Input')\n",
    "bars_out = ax.bar(x + width/2, PII_out, width, color = 'green', label='Output')\n",
    "for bar, pct in zip(bars_in, PII_perc_in):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height, f\"{pct:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "for bar, pct in zip(bars_out, PII_perc_out):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height, f\"{pct:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(f\"PII Check (Output file has {red_out:,} redaction tags)\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'PII_Check.png'), bbox_inches='tight')\n",
    "print(\"Saved: PII_Check.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b776a0",
   "metadata": {},
   "source": [
    "## 4b. Safety: Toxicity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019781c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def count_toxic_docs(df, key=\"text\", threshold=0.5, batch_size=16, sample=None):\n",
    "    \"\"\"\n",
    "    Returns the number of toxic documents per category.\n",
    "    Light enough to run on a personal laptop.\n",
    "    \"\"\"\n",
    "\n",
    "    detox = Detoxify(\"original\")\n",
    "\n",
    "    # Optional sampling for speed\n",
    "    if sample:\n",
    "        df = df.sample(sample, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    texts = df[key].fillna(\"\").tolist()\n",
    "\n",
    "    categories = [\"toxicity\", \"severe_toxicity\", \"obscene\",\n",
    "                  \"identity_attack\", \"insult\", \"threat\"]\n",
    "\n",
    "    # Counter for toxic docs per category\n",
    "    toxic_counts = {cat: 0 for cat in categories}\n",
    "\n",
    "    # Process in small batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Scanning toxicity\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_scores = detox.predict(batch)\n",
    "\n",
    "        # Count doc if > threshold\n",
    "        for cat in categories:\n",
    "            for score in batch_scores[cat]:\n",
    "                if score > threshold:\n",
    "                    toxic_counts[cat] += 1\n",
    "\n",
    "    return toxic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e26d503",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "toxic_docs_in = count_toxic_docs(df_in, sample=SAMPLE_SIZE)\n",
    "toxic_docs_out = count_toxic_docs(df_out, sample=SAMPLE_SIZE)\n",
    "\n",
    "categories = list(toxic_docs_in.keys())\n",
    "\n",
    "x = np.arange(len(categories))         \n",
    "width = 0.35                       \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bars_in = ax.bar(x - width/2, [toxic_docs_in[c] for c in categories],\n",
    "                 width, label='Input', color = 'Orange')\n",
    "\n",
    "bars_out = ax.bar(x + width/2, [toxic_docs_out[c] for c in categories],\n",
    "                  width, label='Output', color = 'Green')\n",
    "\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(f'Toxic Documents (Using Sample size = {SAMPLE_SIZE:.0f})')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "\n",
    "for bar, cat in zip(bars_in, categories):\n",
    "    height = bar.get_height()\n",
    "    pct = 100 * toxic_docs_in[cat] / SAMPLE_SIZE \n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height,\n",
    "            f\"{pct:.1f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "for bar, cat in zip(bars_out, categories):\n",
    "    height = bar.get_height()\n",
    "    pct = 100 * toxic_docs_out[cat] / SAMPLE_SIZE \n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height,\n",
    "            f\"{pct:.1f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'Toxicity_Check.png'), bbox_inches='tight')\n",
    "print(\"Saved: Toxicity_Check.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7c925",
   "metadata": {},
   "source": [
    "## 5. Language distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c82c73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(LANG_MODEL_PATH):\n",
    "    print(\"\\nDownloading FastText model for verification...\")\n",
    "    try:\n",
    "        os.system(f\"wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin -O {LANG_MODEL_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download FastText model automatically: {e}\")\n",
    "        print(\"Please download it manually from the URL above.\")\n",
    "\n",
    "if os.path.exists(LANG_MODEL_PATH):\n",
    "    ft_model = fasttext.load_model(LANG_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae19a8a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_lang(text):\n",
    "    text = text.replace(\"\\n\", \" \")[:1000]\n",
    "    # FastText requires a list for predict\n",
    "    res = ft_model.predict([text])\n",
    "    return res[0][0][0]\n",
    "\n",
    "def english_other_counts(lang_series):\n",
    "    total = len(lang_series)\n",
    "    english = (lang_series == \"en\").sum()\n",
    "    other = total - english\n",
    "    return {\"english\": english, \"other\": other, \"total\": total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11183b45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nVerifying language coverage (input)...\")\n",
    "sample_lang_in = df_in.copy()\n",
    "sample_lang_in['lang'] = df_in['text'].apply(predict_lang)\n",
    "sample_lang_in['lang'] = sample_lang_in['lang'].str.replace('__label__', '')\n",
    "lang_dist_in = sample_lang_in['lang'].value_counts()\n",
    "print(lang_dist_in)\n",
    "print(\"\\nVerifying language coverage (output)...\")\n",
    "sample_lang_out = df_out.copy()\n",
    "sample_lang_out['lang'] = df_out['text'].apply(predict_lang)\n",
    "sample_lang_out['lang'] = sample_lang_out['lang'].str.replace('__label__', '')\n",
    "lang_dist_out = sample_lang_out['lang'].value_counts()\n",
    "print(lang_dist_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03430221",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dist_in = english_other_counts(sample_lang_in[\"lang\"])\n",
    "dist_out = english_other_counts(sample_lang_out[\"lang\"])\n",
    "\n",
    "categories = [\"english\", \"other\"]\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bars_in = ax.bar(x - width/2, [dist_in[c] for c in categories],\n",
    "                 width, label=\"Input\", color = 'Orange')\n",
    "\n",
    "bars_out = ax.bar(x + width/2, [dist_out[c] for c in categories],\n",
    "                  width, label=\"Output\", color = 'Green')\n",
    "\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title('Language Distribution')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([\"English\", \"Other\"], fontsize=12)\n",
    "ax.legend()\n",
    "\n",
    "for bar, cat in zip(bars_in, categories):\n",
    "    height = bar.get_height()\n",
    "    pct = 100 * dist_in[cat] / dist_in[\"total\"]\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height,\n",
    "            f\"{pct:.1f}%\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "for bar, cat in zip(bars_out, categories):\n",
    "    height = bar.get_height()\n",
    "    pct = 100 * dist_out[cat] / dist_out[\"total\"]\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, height,\n",
    "            f\"{pct:.1f}%\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'Language_Check.png'), bbox_inches='tight')\n",
    "print(\"Saved: Language_Check.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330e1c4",
   "metadata": {},
   "source": [
    "## 6. Linguistic (Perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c4822",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_ppl_batch(texts, model, tokenizer, device, stride=512):\n",
    "    ppls = []\n",
    "\n",
    "    for text in texts:\n",
    "        encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        seq_len = input_ids.size(1)\n",
    "        max_length = model.config.n_positions\n",
    "\n",
    "        nlls = []\n",
    "        prev_end_loc = 0\n",
    "\n",
    "        # Sliding window over the sequence\n",
    "        for begin_loc in range(0, seq_len, stride):\n",
    "            end_loc = min(begin_loc + max_length, seq_len)\n",
    "            trg_len = end_loc - prev_end_loc\n",
    "\n",
    "            inp = input_ids[:, begin_loc:end_loc]\n",
    "            target_ids = inp.clone()\n",
    "            target_ids[:, :-trg_len] = -100   # mask everything except last block\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inp, labels=target_ids)\n",
    "                nlls.append(outputs.loss)\n",
    "\n",
    "            prev_end_loc = end_loc\n",
    "            if end_loc >= seq_len:\n",
    "                break\n",
    "\n",
    "        if len(nlls) == 0:\n",
    "            ppls.append(float('nan'))\n",
    "        else:\n",
    "            ppl = torch.exp(torch.stack(nlls).mean()).item()\n",
    "            ppls.append(ppl)\n",
    "\n",
    "    return ppls\n",
    "\n",
    "\n",
    "def compute_dataset_perplexity(df, text_column=\"text\", \n",
    "                               model_id=\"distilgpt2\", \n",
    "                               sample_size=SAMPLE_SIZE,\n",
    "                               batch_size=8):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Loading {model_id} on {device}...\")\n",
    "\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Sample subset\n",
    "    sample = df[text_column].sample(min(len(df), sample_size)).tolist()\n",
    "\n",
    "    print(f\"Computing perplexity on {len(sample)} docs (batch size={batch_size})...\")\n",
    "\n",
    "    all_ppls = []\n",
    "    for i in tqdm(range(0, len(sample), batch_size)):\n",
    "        batch = sample[i:i+batch_size]\n",
    "        batch_ppls = calculate_ppl_batch(batch, model, tokenizer, device)\n",
    "        all_ppls.extend(batch_ppls)\n",
    "\n",
    "    return all_ppls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7053ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ppls_in = compute_dataset_perplexity(df_in)\n",
    "ppls_out = compute_dataset_perplexity(df_out)\n",
    "\n",
    "ppl_mean_in = np.mean(ppls_in)\n",
    "ppl_mean_out = np.mean(ppls_out)\n",
    "ppl_median_in = np.median(ppls_in)\n",
    "ppl_median_out = np.median(ppls_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab459a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "\n",
    "ax[0].hist(ppls_in, color='orange', bins = np.linspace(0, 500, 50))\n",
    "ax[1].hist(ppls_out, color='green', bins = np.linspace(0, 500, 50))\n",
    "ax[0].axvline(ppl_mean_in, color = 'k', ls = '--', lw = 2, label = f'Avg = {ppl_mean_in:.1f}')\n",
    "ax[0].axvline(ppl_median_in, color = 'r', ls = '--', lw = 2, label = f'Median = {ppl_median_in:.1f}')\n",
    "ax[1].axvline(ppl_mean_out, color = 'k', ls = '--', lw = 2, label = f'Avg = {ppl_mean_out:.1f}')\n",
    "ax[1].axvline(ppl_median_out, color = 'r', ls = '--', lw = 2, label = f'Median = {ppl_median_out:.1f}')\n",
    "ax[0].set_title(f\"Perplexity Distribution (Using sample size = {SAMPLE_SIZE:.0f})\")\n",
    "ax[1].set_xlabel(\"Perplexity\")\n",
    "ax[0].set_ylabel(\"Count\")\n",
    "ax[1].set_ylabel(\"Count\")\n",
    "ax[0].legend(frameon=False)\n",
    "ax[1].legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'Perplexity_Dist.png'), bbox_inches='tight')\n",
    "print(\"Saved: Perplexity_Dist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805e6fa",
   "metadata": {},
   "source": [
    "## 7. Deduplication check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f65174",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_docs = len(df_out)\n",
    "unique_ids = df_out['doc_id'].nunique()\n",
    "unique_texts = df_out['text'].nunique()\n",
    "duplicate_texts = total_docs - unique_texts\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "categories = ['Unique', 'Duplicate']\n",
    "values = [unique_ids, duplicate_texts]\n",
    "colors_bar = ['Blue', 'Red']\n",
    "bars = plt.bar(categories, values, color=colors_bar, edgecolor='black', width=0.6)\n",
    "plt.ylabel('Count')\n",
    "plt.yscale('log')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    percentage = (height / total_docs * 100) if total_docs > 0 else 0\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height, f'{int(height):,}\\n({percentage:.2f}%)', ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_DIR, 'Dedup_Check.png'), bbox_inches='tight')\n",
    "print(\"Saved: Dedup_Check.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
